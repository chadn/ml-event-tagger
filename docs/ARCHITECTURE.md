# ğŸ§­ ML Event Tagger â€” Architecture Overview

This document outlines the design, data flow, and integration plan for the **ml-event-tagger** service.

---

## ğŸ¯ Goal

Develop a minimal, well-structured machine learning microservice that can:

-   Train a lightweight text classifier using **TensorFlow/Keras**
-   Serve tag predictions via a **FastAPI** endpoint
-   Integrate with [CMF](https://github.com/chadn/cmf) or other event-based applications

---

## ğŸ§± System Overview

```
+------------------------+          +-----------------------+
|  CMF Client (Next.js)  |  --->    |  ML Event Tagger API  |
|  /api/events           |          |  /predict (FastAPI)   |
+------------------------+          +-----------------------+
         |                                     |
         |<------ Tags merged later -----------|
```

### Integration with CMF

```mermaid
sequenceDiagram
  participant User
  participant CMF as CMF Client
  participant ML as ML Event Tagger

  User->>CMF: Open app
  CMF->>CMF: Fetch /api/events (no tags)
  CMF->>User: Render events on map
  CMF->>ML: Request /predict for visible events
  ML-->>CMF: Return tags
  CMF->>User: Merge and display tags
```

---

## ğŸ§© Components

### 1ï¸âƒ£ Training Pipeline

-   Located in `ml_event_tagger/train.py` and `notebooks/`.
-   Reads labeled data (`data/labeled_events.json`).
-   Preprocesses text: concatenates `name + description + location`
-   Uses Tokenizer + Sequential Keras model:
    -   Embedding â†’ GlobalAveragePooling1D â†’ Dense(32, relu) â†’ Dense(n_tags, sigmoid)
-   Data split: 70% train / 15% validation / 15% test
-   Produces:
    -   `models/tagger_v1_YYYYMMDD.h5` (model weights)
    -   `models/tokenizer_v1.pkl` (tokenizer)
    -   `models/metrics_v1.json` (evaluation results)
-   Evaluates: precision, recall, F1-score per tag, confusion matrix

**Model versioning:** Models saved with version and date, allowing regression tests and performance comparison.

### 2ï¸âƒ£ Serving Layer

-   FastAPI app (`ml_event_tagger/serve.py`).
-   Loads pre-trained model and tokenizer at startup.
-   Exposes endpoints:
    -   `GET /health` - Health check
    -   `POST /predict` - Tag prediction
-   Returns top-5 tags with confidence scores per event.

### 3ï¸âƒ£ Data & Tags

-   **Static labeled dataset** in MVP (~100 events from CMF)
-   **Tag taxonomy:** 15-20 predefined tags (see [TAGS.md](./TAGS.md))
-   Future: adapters for live event fetching from multiple sources

---

## âš™ï¸ Data Flow

### Training Phase

1. Load labeled events from `data/labeled_events.json`
2. Preprocess text:
    - Concatenate: `name + " " + description + " " + location`
    - Lowercase, remove URLs, strip HTML tags
    - Tokenize with max sequence length
3. Split data: 70% train / 15% validation / 15% test
4. Train multi-label classifier
5. Evaluate on test set
6. Save model, tokenizer, and metrics

### Inference Phase

1. Client sends events via `/predict` endpoint
2. Preprocess text (same pipeline as training)
3. Tokenize and pad sequences
4. Model predicts tag probabilities
5. Return top-5 tags sorted by confidence

---

## ğŸ§© API Contract

### POST /predict

**Request:**

```json
{
    "events": [
        {
            "name": "Days Like This - House Music",
            "description": "Weekly house music gathering with local DJs",
            "location": "The Pergola at Lake Merritt, 599 El Embarcadero, Oakland, CA 94610, USA"
        }
    ]
}
```

**Response:**

```json
{
    "predictions": [
        {
            "tags": [
                { "name": "music", "confidence": 0.92 },
                { "name": "house", "confidence": 0.87 },
                { "name": "oakland", "confidence": 0.86 },
                { "name": "dance", "confidence": 0.78 },
                { "name": "weekly", "confidence": 0.65 }
            ]
        }
    ]
}
```

**Notes:**

-   `location` is optional but recommended for better predictions
-   Returns top-5 tags sorted by confidence (descending)
-   Confidence values are between 0.0 and 1.0

### GET /health

**Response:**

```json
{
    "status": "healthy",
    "model_loaded": true,
    "version": "0.1.0"
}
```

---

## ğŸš€ Integration with CMF

**Client-side enrichment (recommended MVP):**

-   CMF loads map events instantly.
-   Background task calls `/predict` for all visible events.
-   Updates UI with suggested tags once received.

**Alternative (later):**

-   CMF backend `/api/events` merges tags server-side and caches results.

---

## ğŸ“Š Training Strategy

### Model Architecture

```
Input (text sequences)
    â†“
Embedding(vocab_size=5000, embedding_dim=64)
    â†“
GlobalAveragePooling1D()
    â†“
Dense(32, activation='relu')
    â†“
Dense(n_tags, activation='sigmoid')
```

### Hyperparameters

-   **Vocabulary size:** 5000 tokens
-   **Embedding dimension:** 64
-   **Max sequence length:** 100 tokens
-   **Dense layer size:** 32 neurons
-   **Batch size:** 16
-   **Epochs:** 20-30 (with early stopping)
-   **Optimizer:** Adam (lr=0.001)
-   **Loss:** Binary crossentropy

### Evaluation Metrics

**Primary metrics:**

-   Macro-averaged precision (â‰¥60% target)
-   Macro-averaged recall (â‰¥40% target)
-   Per-tag precision and recall

**Visualizations:**

-   Confusion matrix heatmap
-   Tag frequency distribution
-   Precision/Recall bar charts per tag
-   Training/validation loss curves

---

## ğŸ§± Repository Structure

```
ml-event-tagger/
â”œâ”€â”€ ml_event_tagger/           # Main package
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ train.py               # Training script
â”‚   â”œâ”€â”€ serve.py               # FastAPI app
â”‚   â”œâ”€â”€ preprocess.py          # Text preprocessing
â”‚   â”œâ”€â”€ model.py               # Model architecture
â”‚   â””â”€â”€ config.py              # Configuration
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ 01_train_and_evaluate.ipynb
â”œâ”€â”€ models/                     # Saved models (gitignored)
â”œâ”€â”€ data/
â”‚   â””â”€â”€ labeled_events.json
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_api.py
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ ARCHITECTURE.md         # This file
â”‚   â”œâ”€â”€ ROADMAP.md
â”‚   â”œâ”€â”€ MVP_DECISIONS.md
â”‚   â”œâ”€â”€ IMPLEMENTATION_PLAN.md
â”‚   â”œâ”€â”€ TAGS.md
â”‚   â””â”€â”€ VERSION_MANAGEMENT.md
â”œâ”€â”€ pyproject.toml              # Dependencies & project config
â”œâ”€â”€ requirements.txt            # Legacy (kept for compatibility)
â”œâ”€â”€ CHANGELOG.md
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## ğŸ§° Deployment Plan

**MVP Deployment:**

-   Dockerfile with Python 3.11+ slim image
-   FastAPI with Uvicorn server
-   Expose port 8080
-   Deploy to Render.com (preferred) Fly.io, or Hugging Face Spaces

---

## âœ… Success Criteria

-   **Model Performance:** â‰¥60% macro-averaged precision on test data
-   **System Performance:** <300ms inference time (p95 latency)
-   **End-to-End:** Working pipeline from training to serving
-   **Reproducibility:** Clone to first prediction in ~10 minutes
-   **Code Quality:** Clean, documented, testable code
